{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "studies = pd.read_csv(\"../resources/processed-goldstandard-CT.tsv\", sep = '\\t', encoding='utf8')\n",
    "studies.fillna(\"\", inplace=True)\n",
    "studies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\"official_title\",\n",
    "                \"brief_summary\",\n",
    "                \"detailed_description\",\n",
    "                \"study_design_info\",\n",
    "                \"outcomes\",\n",
    "                \"conditions\",\n",
    "                \"arm_groups\",\n",
    "                \"drug_interventions\",\n",
    "                \"other_interventions\",\n",
    "                \"inclusion_criteria\",\n",
    "                \"mesh_terms_conditions\",\n",
    "                \"mesh_terms_interventions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies[\"conditions\"]= studies[\"conditions\"].str.replace(\";\", \" \")\n",
    "studies[\"mesh_terms_conditions\"]= studies[\"mesh_terms_conditions\"].str.replace(\";\", \" \")\n",
    "studies[\"mesh_terms_interventions\"]= studies[\"mesh_terms_interventions\"].str.replace(\";\", \" \")\n",
    "studies[\"drug_interventions\"]= studies[\"drug_interventions\"].str.replace(\";\", \" \")\n",
    "studies[\"other_interventions\"]= studies[\"other_interventions\"].str.replace(\";\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    for f in feature_names:\n",
    "        print(f + \": \" + str(studies.loc[i+1, f]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies['X'] = studies.apply(lambda r: ' '.join(r[feature] for feature in feature_names), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies[\"X\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(studies['pm_rel_desc'])\n",
    "\n",
    "studies[\"pm\"] = 0\n",
    "studies[\"pm\"][studies[\"pm_rel_desc\"] == \"Human PM\"] = 1\n",
    "studies[\"pm\"][studies[\"pm_rel_desc\"] == \"Animal PM\"] = 1\n",
    "studies[\"pm\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(studies.pm == 0))\n",
    "print(sum(studies.pm == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(studies['X'], studies['pm'], test_size=0.25, random_state=33)\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train instance: \", X_train[1])\n",
    "print(\"y_train instance: \", y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Encode from string to numbers\n",
    "enc = preprocessing.LabelEncoder()\n",
    "y_train = enc.fit_transform(y_train)\n",
    "y_test = enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def stemming_tokenizer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 10000\n",
    "vectorizer = TfidfVectorizer(tokenizer=stemming_tokenizer,\n",
    "                             stop_words=stopwords.words('english') + list(string.punctuation),lowercase = True, max_features = n_words)\n",
    "tfidf = vectorizer.fit(X_train.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf.transform(X_test.values.astype('U'))\n",
    "X_train = tfidf.transform(X_train.values.astype('U'))\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=10800#1200#86400\n",
    ")\n",
    "automl.fit(X_train, y_train)\n",
    "y_hat = automl.predict(X_test)\n",
    "print(\"Final Models:\", automl.show_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix: \\n\", sklearn.metrics.confusion_matrix(y_test, y_hat, labels=[1,0]))\n",
    "print(\"Precision: \", sklearn.metrics.precision_score(y_test, y_hat))\n",
    "print(\"Recall: \", sklearn.metrics.recall_score(y_test, y_hat))\n",
    "print(\"Accuracy: \", sklearn.metrics.accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "VECTORIZER_NAME = \"../models/tfidfmodel_studies.sav\"\n",
    "pickle.dump(tfidf, open(VECTORIZER_NAME, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = \"trec_model_studies.sav\"\n",
    "pickle.dump(automl, open(MODELNAME, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(MODELNAME, 'rb'))\n",
    "y_hat2 = loaded_model.predict(X_test)\n",
    "print(\"Accuracy: \", sklearn.metrics.accuracy_score(y_test, y_hat2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
