{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldfile   = \"../../resources/20180622processedGoldStandardTopics.tsv.gz\"\n",
    "resultsdir = \"../../results_disease_2017/\"\n",
    "statsdir   = \"../../stats_disease_2017/\"\n",
    "measures   = [\"ndcg\",\"infNDCG\", \"P_10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allgsdf = pd.read_csv(goldfile, delimiter=\"\\t\")\n",
    "gsdf = allgsdf.drop([\"title\", \"abstract\", \"major_mesh\", \"minor_mesh\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRelFoundCounts(dir):\n",
    "    # Read all results in the given result directory\n",
    "    resultfiles = sorted(os.listdir(dir))\n",
    "    # Read the result files as DataFrames into a map\n",
    "    resultdfmap = []\n",
    "    for f in resultfiles:\n",
    "        resultdfmap.append(pd.read_csv(dir+f, delimiter=\"\\t\", names=[\"topic\", \"Q0\", \"docid\", \"rank\", \"score\", \"run\"]))\n",
    "    # Create a DataFrame multiindexed with the file name (because those are the keys of the DF maps)\n",
    "    resultmultidxdf = pd.concat(resultdfmap)\n",
    "    resultmultidxdf.set_index([\"run\"], inplace=True)\n",
    "    \n",
    "    # Create a duplication of the relevant GS document to match the results\n",
    "    gsreldocs = gsdf.query(\"relevance_score > 0\")[[\"trec_topic_number\", \"trec_doc_id\"]]\n",
    "    l = []\n",
    "    for experiment in set(resultmultidxdf.index):\n",
    "        idx = pd.Index([experiment]*len(gsreldocs), name=\"run\")\n",
    "        gscopy = gsreldocs.copy()\n",
    "        gscopy.index = idx\n",
    "        l.append(gscopy)\n",
    "    gsdfs = pd.concat(l)\n",
    "    \n",
    "    # Merge the duplicated GS with the results\n",
    "    # With a `left` join, thus eliminating all irrelevant documents.\n",
    "    relmerge = pd.merge(gsdfs, resultmultidxdf, how=\"left\", left_on=[\"run\", \"trec_topic_number\", \"trec_doc_id\"], right_on=[\"run\", \"topic\", \"docid\"])\n",
    "    relmerge.set_index(\"trec_topic_number\", append=\"True\", inplace=True)\n",
    "    \n",
    "    # Count the number of found documents per run and topic    \n",
    "    countsruntopic = relmerge.groupby([\"run\", \"trec_topic_number\"]).count()\n",
    "    countsruntopic = countsruntopic.drop([\"Q0\", \"docid\", \"rank\", \"score\"],axis=1)\n",
    "    countsruntopic.columns = [\"relgs\", \"relfound\"]\n",
    "    \n",
    "    # return the left-merged data and the counts\n",
    "    return relmerge,countsruntopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareStats(path):\n",
    "    \"\"\"\n",
    "    Reads a single stats CSV file, excludes the 'all' row and converts the topic numbers to ints.\n",
    "    Then sets the Topic columns as the new index.\n",
    "    Returns a DataFrame indexed by the non-'all' topics.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path).query(\"Topic != 'all'\")\n",
    "    df[\"Topic\"] = df[\"Topic\"].astype(int)\n",
    "    df.sort_values(by=\"Topic\", inplace=True)\n",
    "    df = df.set_index(\"Topic\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanStatsPerRun(statspath):\n",
    "    \"\"\"\n",
    "    Reads a directory of stat CSV files. Concatenates all the DataFrames and calculates the means for all\n",
    "    score measurements of the topics per run, effectively returning the 'all' row for each run. Note,\n",
    "    however, that really just the mean over the measures is given which should be the 'all' value but the actual\n",
    "    'all' value is not used here.\n",
    "    Returns only those measures defined in the 'measures' list at the beginning of this cell.\n",
    "    \"\"\"\n",
    "    statfiles = sorted(list(filter(lambda f: f.endswith(\".csv\"), os.listdir(statspath))))\n",
    "    runstatsmap = {}\n",
    "    for stat in statfiles:\n",
    "        df = prepareStats(statspath+stat)\n",
    "        run = stat.replace(\"OFFICIAL_\", \"\").replace(\".csv\", \"\")\n",
    "        runstatsmap[run] = df\n",
    "    allstats = pd.concat(runstatsmap)\n",
    "    allstats.index.names = [\"run\", \"Topic\"]\n",
    "    allstats = allstats[measures]\n",
    "    meanstats = allstats.mean(level=\"run\")\n",
    "    return meanstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelFoundWithMeanRank(resultspath, statspath):\n",
    "    gsleftmerged,counts = calculateRelFoundCounts(resultspath)\n",
    "    meanstats = getMeanStatsPerRun(statspath)\n",
    "    counts    = counts.sum(level=\"run\").sort_values(\"relfound\")\n",
    "    merge     = pd.merge(counts, meanstats, on=\"run\")\n",
    "    meanranks = gsleftmerged[\"rank\"].dropna().mean(level=\"run\")\n",
    "    stdranks  = gsleftmerged[\"rank\"].dropna().std(level=\"run\")\n",
    "    merge[\"meanrank\"] = meanranks\n",
    "    merge[\"stdrank\"] = stdranks\n",
    "    return merge.sort_values(\"relfound\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg</th>\n",
       "      <th>infNDCG</th>\n",
       "      <th>P_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dishyper--dis1.0-hyp0.0-syn0.0</th>\n",
       "      <td>0.504927</td>\n",
       "      <td>0.352660</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dishyper--dis1.0-hyp0.0-syn1.0</th>\n",
       "      <td>0.504927</td>\n",
       "      <td>0.352660</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dishyper--dis1.0-hyp1.0-syn0.0</th>\n",
       "      <td>0.446457</td>\n",
       "      <td>0.281613</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dishyper--dis1.0-hyp1.0-syn1.0</th>\n",
       "      <td>0.446457</td>\n",
       "      <td>0.281613</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dissyn--dis1.0-hyp0.0-syn0.0</th>\n",
       "      <td>0.529317</td>\n",
       "      <td>0.388357</td>\n",
       "      <td>0.486667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dissyn--dis1.0-hyp0.0-syn1.0</th>\n",
       "      <td>0.535060</td>\n",
       "      <td>0.391587</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dissyn--dis1.0-hyp1.0-syn0.0</th>\n",
       "      <td>0.529317</td>\n",
       "      <td>0.388357</td>\n",
       "      <td>0.486667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dissyn--dis1.0-hyp1.0-syn1.0</th>\n",
       "      <td>0.535060</td>\n",
       "      <td>0.391587</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dissynhyper--dis1.0-hyp0.0-syn0.0</th>\n",
       "      <td>0.504927</td>\n",
       "      <td>0.352660</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dissynhyper--dis1.0-hyp0.0-syn1.0</th>\n",
       "      <td>0.513820</td>\n",
       "      <td>0.358230</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dissynhyper--dis1.0-hyp1.0-syn0.0</th>\n",
       "      <td>0.446457</td>\n",
       "      <td>0.281613</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dissynhyper--dis1.0-hyp1.0-syn1.0</th>\n",
       "      <td>0.452020</td>\n",
       "      <td>0.285387</td>\n",
       "      <td>0.370000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ndcg   infNDCG      P_10\n",
       "run                                                            \n",
       "dishyper--dis1.0-hyp0.0-syn0.0     0.504927  0.352660  0.453333\n",
       "dishyper--dis1.0-hyp0.0-syn1.0     0.504927  0.352660  0.453333\n",
       "dishyper--dis1.0-hyp1.0-syn0.0     0.446457  0.281613  0.366667\n",
       "dishyper--dis1.0-hyp1.0-syn1.0     0.446457  0.281613  0.366667\n",
       "dissyn--dis1.0-hyp0.0-syn0.0       0.529317  0.388357  0.486667\n",
       "dissyn--dis1.0-hyp0.0-syn1.0       0.535060  0.391587  0.483333\n",
       "dissyn--dis1.0-hyp1.0-syn0.0       0.529317  0.388357  0.486667\n",
       "dissyn--dis1.0-hyp1.0-syn1.0       0.535060  0.391587  0.483333\n",
       "dissynhyper--dis1.0-hyp0.0-syn0.0  0.504927  0.352660  0.453333\n",
       "dissynhyper--dis1.0-hyp0.0-syn1.0  0.513820  0.358230  0.453333\n",
       "dissynhyper--dis1.0-hyp1.0-syn0.0  0.446457  0.281613  0.366667\n",
       "dissynhyper--dis1.0-hyp1.0-syn1.0  0.452020  0.285387  0.370000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMeanStatsPerRun(statsdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result () {'run': 'DSYN_DHYP_DPT_GSYN_WR', 'multfields': 'phrase', 'op': 'OR', 'wordremoval': 'false', 'slop': '5.trec_results.gz'}>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from parse import *\n",
    "s = \"DSYN_DHYP_DPT_GSYN_WR--mmm:phrase-op:OR-wr:false-sl:5.trec_results.gz\"\n",
    "filenameformat = \"{run}--mmm:{multfields}-op:{op}-wr:{wordremoval}-sl:{slop}\"\n",
    "parse(filenameformat, s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
